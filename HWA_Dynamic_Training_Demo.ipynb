{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "sg8v1SCn6HSe"
      },
      "outputs": [],
      "source": [
        "!pip install aihwkit\n",
        "!wget https://aihwkit-gpu-demo.s3.us-east.cloud-object-storage.appdomain.cloud/aihwkit-0.9.1+cuda117-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n",
        "!pip install aihwkit-0.9.1+cuda117-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "MTL Model Adapted from: https://medium.com/@aminul.huq11/multi-task-learning-a-beginners-guide-a1fc17808688"
      ],
      "metadata": {
        "id": "sSvy6RsKPHUx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/aminul-huq/medium.git"
      ],
      "metadata": {
        "id": "TNAf_VMxNqYl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd medium/mammogram\n",
        "import random\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as datasets\n",
        "from torch.utils.data import DataLoader,random_split,Dataset\n",
        "import torch.optim as optim\n",
        "from tqdm import tqdm\n",
        "from training_utils import *"
      ],
      "metadata": {
        "id": "iXWwVizEN1oJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seed = 43\n",
        "random.seed(seed)\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "\n",
        "torch.backends.cudnn.deterministic = True"
      ],
      "metadata": {
        "id": "D-tw00Y7N8PV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainset = datasets.CIFAR10(root='./data/', train=True, download=True, transform=transforms.ToTensor())\n",
        "testset = datasets.CIFAR10(root='./data/', train=False, download=True, transform=transforms.ToTensor())\n",
        "\n",
        "labels_list = ['airplane','automobile','bird','cat','deer','dog','frog','horse','ship','truck']\n",
        "non_animal = [0,1,8,9]\n",
        "device = 'cuda'"
      ],
      "metadata": {
        "id": "inAacJesN9CD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "978f6f50-8479-457b-d3c7-e0bce2463814"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class NewDataset(Dataset):\n",
        "\n",
        "    def __init__(self,data,transform=None):\n",
        "        self.data = data\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self,idx):\n",
        "        image = self.data[idx][0]\n",
        "        label1 = self.data[idx][1]                                  #original label\n",
        "        label2 = 0 if self.data[idx][1] in non_animal else 1        #animal or non-animal\n",
        "        return image, label1, label2"
      ],
      "metadata": {
        "id": "H0UEJZhVOHAP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_trainset = NewDataset(trainset,non_animal)\n",
        "new_testset = NewDataset(testset,non_animal)\n",
        "\n",
        "train_set, valid_set = random_split(new_trainset,[int(len(new_trainset)*0.9), int(len(new_trainset)*0.1)],\n",
        "                                  generator=torch.Generator().manual_seed(0))\n",
        "\n",
        "train_loader = DataLoader(train_set, batch_size=100, shuffle=True)\n",
        "valid_loader = DataLoader(valid_set, batch_size=100, shuffle=True)\n",
        "test_loader = DataLoader(new_testset, batch_size=100, shuffle=True)"
      ],
      "metadata": {
        "id": "_zP8MAZ2OIkC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from aihwkit.simulator.configs import InferenceRPUConfig\n",
        "from aihwkit.nn import AnalogLinear\n",
        "from aihwkit.optim import AnalogSGD\n",
        "from aihwkit.simulator.configs import (\n",
        "    InferenceRPUConfig,\n",
        "    WeightNoiseType,\n",
        "    WeightClipType,\n",
        "    WeightModifierType,\n",
        "    WeightRemapType,\n",
        ")\n",
        "from aihwkit.nn import AnalogConv2d, AnalogLinear, AnalogSequential\n",
        "from aihwkit.inference import PCMLikeNoiseModel, GlobalDriftCompensation\n",
        "from aihwkit.simulator.parameters import IOParameters"
      ],
      "metadata": {
        "id": "5y0XMlgOM9_6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_rpu_config(g_max=25, tile_size=512, modifier_std=0.07):\n",
        "  rpu_config = InferenceRPUConfig()\n",
        "  rpu_config.mapping.digital_bias = True\n",
        "  rpu_config.mapping.weight_scaling_omega = 1.0\n",
        "  rpu_config.mapping.weight_scaling_columnwise = True\n",
        "  rpu_config.mapping.learn_out_scaling = True\n",
        "  rpu_config.mapping.out_scaling_columnwise = True\n",
        "  rpu_config.mapping.max_input_size = tile_size\n",
        "  rpu_config.mapping.max_output_size = tile_size\n",
        "  rpu_config.noise_model = PCMLikeNoiseModel(g_max=g_max)\n",
        "  rpu_config.remap.type = WeightRemapType.CHANNELWISE_SYMMETRIC\n",
        "  rpu_config.clip.type = WeightClipType.FIXED_VALUE\n",
        "  rpu_config.clip.fixed_value = 1.0\n",
        "  rpu_config.modifier.type = WeightModifierType.MULT_NORMAL\n",
        "  rpu_config.modifier.rel_to_actual_wmax = True\n",
        "  rpu_config.modifier.std_dev = modifier_std\n",
        "  rpu_config.forward = IOParameters()\n",
        "  rpu_config.forward.out_noise = 0.05\n",
        "  rpu_config.forward.inp_res = 1 / (2 ** 8 - 2)\n",
        "  rpu_config.forward.out_res = 1 / (2 ** 8 - 2)\n",
        "  rpu_config.drift_compensation = GlobalDriftCompensation()\n",
        "  return rpu_config"
      ],
      "metadata": {
        "id": "4wDcWgI08G44"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_hardware_metrics(rpu_config, outputs):\n",
        "    temperature = float(np.random.uniform(0.8, 1.2) * rpu_config.forward.inp_res * rpu_config.forward.out_res)\n",
        "    noise = float(np.random.uniform(0.8, 1.2) * rpu_config.forward.out_noise)\n",
        "    drift = float(rpu_config.drift_compensation.readout(outputs))\n",
        "    return temperature, noise, drift"
      ],
      "metadata": {
        "id": "V9S-SKtSvMGZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_hardware_loss(rpu_config, outputs):\n",
        "  temperature, noise, drift = compute_hardware_metrics(rpu_config, outputs)\n",
        "  temperature = torch.tensor(temperature, device=outputs.device)\n",
        "  hardware_loss = 0.2 * temperature + 0.3 * noise + 0.2 * drift\n",
        "  return hardware_loss"
      ],
      "metadata": {
        "id": "HsxQbJbACDqG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def update_rpu_config(rpu_config, perturbation_scale=0.01):\n",
        "  rpu_config.forward.inp_res += rpu_config.forward.inp_res * perturbation_scale\n",
        "  rpu_config.forward.out_res += rpu_config.forward.inp_res * perturbation_scale\n",
        "  rpu_config.forward.out_noise += rpu_config.forward.inp_res * perturbation_scale\n",
        "  g_max = rpu_config.noise_model.g_max + rpu_config.noise_model.g_max * perturbation_scale\n",
        "  rpu_config.noise_model = PCMLikeNoiseModel(g_max)\n",
        "  rpu_config.modifier.std_dev += rpu_config.modifier.std_dev * perturbation_scale"
      ],
      "metadata": {
        "id": "2MZdbvOsE3xC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DynamicLayer(nn.Module):\n",
        "    def __init__(self, layer_type, *args, **kwargs):\n",
        "\n",
        "        super(DynamicLayer, self).__init__()\n",
        "        self.layer_type = layer_type\n",
        "        self.args = args\n",
        "        self.kwargs = kwargs\n",
        "\n",
        "        rpu_config = create_rpu_config()\n",
        "        if layer_type == 'conv':\n",
        "            self.analog_layer = AnalogConv2d(*args, **kwargs, rpu_config=rpu_config)\n",
        "            self.digital_layer = nn.Conv2d(*args, **kwargs)\n",
        "        elif layer_type == 'linear':\n",
        "            self.analog_layer = AnalogLinear(*args, **kwargs, rpu_config=rpu_config)\n",
        "            self.digital_layer = nn.Linear(*args, **kwargs)\n",
        "        else:\n",
        "            raise ValueError(\"Invalid layer_type. Use 'conv' or 'linear'.\")\n",
        "        self.is_analog = False\n",
        "\n",
        "    def forward(self, x):\n",
        "        if self.is_analog:\n",
        "            return self.analog_layer(x)\n",
        "        else:\n",
        "            return self.digital_layer(x)\n",
        "\n",
        "    def toggle(self, is_analog):\n",
        "\n",
        "        self.is_analog = is_analog\n",
        "        # If switching to analog, synchronize weights\n",
        "        if self.is_analog:\n",
        "            if self.layer_type == 'conv':\n",
        "                self.analog_layer.set_weights(self.digital_layer.weight.detach().cpu().numpy().reshape(-1))\n",
        "            elif self.layer_type == 'linear':\n",
        "                self.analog_layer.set_weights(self.digital_layer.weight.detach().cpu().numpy(),\n",
        "                                               self.digital_layer.bias.detach().cpu().numpy())\n",
        "\n",
        "        # If switching to digital, synchronize weights\n",
        "        else:\n",
        "            if self.layer_type == 'conv':\n",
        "                weights = torch.tensor(self.analog_layer.get_weights()[0]).reshape(self.digital_layer.weight.shape)\n",
        "                self.digital_layer.weight.data.copy_(weights)\n",
        "            elif self.layer_type == 'linear':\n",
        "                weights, bias = self.analog_layer.get_weights()\n",
        "                self.digital_layer.weight.data.copy_(torch.tensor(weights))\n",
        "                self.digital_layer.bias.data.copy_(torch.tensor(bias))"
      ],
      "metadata": {
        "id": "XDu1mkJOHDyt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MTL_Net_DynamicToggle(nn.Module):\n",
        "    def __init__(self, input_channel, num_class):\n",
        "        super(MTL_Net_DynamicToggle, self).__init__()\n",
        "        self.classes = num_class\n",
        "\n",
        "        # Replace layers with dynamic layers\n",
        "        self.conv1 = DynamicLayer('conv', in_channels=input_channel, out_channels=8, kernel_size=3, stride=1)\n",
        "        self.conv2 = DynamicLayer('conv', in_channels=8, out_channels=16, kernel_size=3, stride=1)\n",
        "        self.fc1 = DynamicLayer('linear', 64, 256)\n",
        "        self.dropout1 = nn.Dropout(0.3)\n",
        "        self.fc2 = DynamicLayer('linear', 256, 128)\n",
        "        self.dropout2 = nn.Dropout(0.3)\n",
        "\n",
        "        # Task-specific layers remain digital\n",
        "        self.fc3 = DynamicLayer('linear', 128, self.classes[0])\n",
        "        self.fc4 = DynamicLayer('linear', 128, self.classes[1])\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.max_pool2d(F.relu(self.conv1(x)), kernel_size=3)\n",
        "        x = F.max_pool2d(F.relu(self.conv2(x)), kernel_size=3)\n",
        "        x = F.relu(self.fc1(x.reshape(-1, x.shape[1] * x.shape[2] * x.shape[3])))\n",
        "        x = self.dropout1(x)\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.dropout2(x)\n",
        "        x1 = self.fc3(x)  # Task 1 output\n",
        "        x2 = self.fc4(x)  # Task 2 output\n",
        "\n",
        "        return x1, x2\n",
        "\n",
        "    def toggle_layer(self, layer_name, is_analog):\n",
        "        \"\"\"\n",
        "        Toggle a specific layer between analog and digital.\n",
        "        \"\"\"\n",
        "        getattr(self, layer_name).toggle(is_analog)"
      ],
      "metadata": {
        "id": "x2RxMQfOHazi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model_dynamic(model, trainloader, optim, criterion, epoch, device, rpu_config, toggle_config=None):\n",
        "    \"\"\"\n",
        "    Train function with dynamic analog/digital toggling.\n",
        "\n",
        "    Parameters:\n",
        "    - toggle_config: dict, specifies which layers to toggle and when during training.\n",
        "                     Example: {'conv1': True, 'fc1': False}.\n",
        "    \"\"\"\n",
        "    model.train()  # Ensure the model is in training mode\n",
        "    train_loss, total, total_correct1, total_correct2 = 0, 0, 0, 0\n",
        "\n",
        "    # Apply toggling at the start of training (if toggle_config is provided)\n",
        "    if toggle_config:\n",
        "        for layer_name, is_analog in toggle_config.items():\n",
        "            model.toggle_layer(layer_name, is_analog)\n",
        "\n",
        "    prev_loss = 0\n",
        "    for i, (inputs, tg1, tg2) in enumerate(tqdm(trainloader)):\n",
        "        inputs, tg1, tg2 = inputs.to(device), tg1.to(device), tg2.to(device)\n",
        "        optim.zero_grad()\n",
        "\n",
        "        # Forward pass through the model\n",
        "        op1, op2 = model(inputs)\n",
        "\n",
        "        # Compute losses for both tasks\n",
        "        loss1 = criterion(op1, tg1)\n",
        "        loss2 = criterion(op2, tg2)\n",
        "        total_loss = loss1 + loss2\n",
        "\n",
        "        hardware_loss = compute_hardware_loss(rpu_config, op1) + compute_hardware_loss(rpu_config, op2)\n",
        "        total_loss += hardware_loss\n",
        "\n",
        "        # Backpropagation\n",
        "        total_loss.backward()\n",
        "\n",
        "        # Update weights\n",
        "        optim.step()\n",
        "\n",
        "        # Accumulate metrics\n",
        "        train_loss += total_loss.item()\n",
        "        _, pd1 = torch.max(op1.data, 1)\n",
        "        _, pd2 = torch.max(op2.data, 1)\n",
        "\n",
        "        total_correct1 += (pd1 == tg1).sum().item()\n",
        "        total_correct2 += (pd2 == tg2).sum().item()\n",
        "        total += tg1.size(0)\n",
        "\n",
        "        if total_loss < prev_loss:\n",
        "            update_rpu_config(rpu_config, total_loss*0.000001)\n",
        "        prev_loss = total_loss\n",
        "\n",
        "    print(\"Epoch: [{}]  loss: [{:.2f}] Original_task_acc [{:.2f}] animal_vs_non_animal_acc [{:.2f}]\".format(\n",
        "        epoch + 1, train_loss / (i + 1),\n",
        "        (total_correct1 * 100 / total),\n",
        "        (total_correct2 * 100 / total)\n",
        "    ))\n",
        "\n",
        "    return train_loss / (i + 1), (total_correct1 * 100 / total), (total_correct2 * 100 / total)"
      ],
      "metadata": {
        "id": "mM49uFNsDfVi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_model_dynamic(model, testloader, criterion, epoch, device, toggle_config=None):\n",
        "    \"\"\"\n",
        "    Test function with dynamic analog/digital toggling.\n",
        "\n",
        "    Parameters:\n",
        "    - toggle_config: dict, specifies which layers to toggle during testing.\n",
        "                     Example: {'conv1': True, 'fc1': False}.\n",
        "    \"\"\"\n",
        "    model.eval()  # Ensure the model is in evaluation mode\n",
        "    test_loss, total, total_correct1, total_correct2 = 0, 0, 0, 0\n",
        "\n",
        "    # Apply toggling at the start of testing (if toggle_config is provided)\n",
        "    if toggle_config:\n",
        "        for layer_name, is_analog in toggle_config.items():\n",
        "            model.toggle_layer(layer_name, is_analog)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i, (inputs, tg1, tg2) in enumerate(tqdm(testloader)):\n",
        "            inputs, tg1, tg2 = inputs.to(device), tg1.to(device), tg2.to(device)\n",
        "\n",
        "            # Forward pass through the model\n",
        "            op1, op2 = model(inputs)\n",
        "\n",
        "            # Compute losses for both tasks\n",
        "            loss1 = criterion(op1, tg1)\n",
        "            loss2 = criterion(op2, tg2)\n",
        "\n",
        "            # Accumulate metrics\n",
        "            test_loss += loss1.item() + loss2.item()\n",
        "            _, pd1 = torch.max(op1.data, 1)\n",
        "            _, pd2 = torch.max(op2.data, 1)\n",
        "\n",
        "            total_correct1 += (pd1 == tg1).sum().item()\n",
        "            total_correct2 += (pd2 == tg2).sum().item()\n",
        "            total += tg1.size(0)\n",
        "\n",
        "    # Compute accuracies\n",
        "    acc1 = 100. * total_correct1 / total\n",
        "    acc2 = 100. * total_correct2 / total\n",
        "\n",
        "    # Log metrics\n",
        "    print(\"Test Epoch: [{}]  loss: [{:.2f}] Original_task_Acc [{:.2f}] animal_vs_non_animal_acc [{:.2f}]\".format(\n",
        "        epoch + 1, test_loss / (i + 1), acc1, acc2\n",
        "    ))\n",
        "\n",
        "    return test_loss / (i + 1), acc1, acc2"
      ],
      "metadata": {
        "id": "W69QZdvmHOaz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_sgd_optimizer(model, learning_rate):\n",
        "    optimizer = AnalogSGD(model.parameters(), lr=learning_rate)\n",
        "    optimizer.regroup_param_groups(model)\n",
        "    return optimizer"
      ],
      "metadata": {
        "id": "2EMdEGnoJZGJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = MTL_Net_DynamicToggle(input_channel=3, num_class=[10, 2]).to('cuda')\n",
        "\n",
        "# Start with all analog\n",
        "model.toggle_layer('conv1', is_analog=True)\n",
        "model.toggle_layer('conv2', is_analog=True)\n",
        "model.toggle_layer('fc1', is_analog=True)\n",
        "model.toggle_layer('fc2', is_analog=True)\n",
        "model.toggle_layer('fc3', is_analog=True)\n",
        "model.toggle_layer('fc4', is_analog=True)\n",
        "\n",
        "optimizer = create_sgd_optimizer(model, 0.01)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "rpu_config = create_rpu_config()\n",
        "\n",
        "order = ['conv1', 'conv1',('fc1', 'fc2'),('fc3','fc4')]\n",
        "\n",
        "for epoch in range(50):\n",
        "    toggle_config = dict()\n",
        "    # Dynamically toggle during training\n",
        "    train_loss, l1, l2 = train_model_dynamic(model, train_loader, optimizer, criterion, epoch, 'cuda', rpu_config, toggle_config)\n",
        "    if train_loss > 0.8 and order:\n",
        "      val = order.pop()\n",
        "      toggle_config = dict()\n",
        "      if type(val) is tuple:\n",
        "          if val[0] > val[1]:\n",
        "            toggle_config[val[1]] = False\n",
        "            order.append(val[0])\n",
        "          else:\n",
        "            toggle_config[val[0]] = False\n",
        "            order.append(val[1])\n",
        "      else:\n",
        "          toggle_config[val] = False\n",
        "    else:\n",
        "      toggle_config = None\n",
        "\n",
        "    # Dynamically toggle during testing\n",
        "    test_loss, acc1, acc2 = test_model_dynamic(model, test_loader, criterion, epoch, 'cuda', toggle_config)"
      ],
      "metadata": {
        "id": "4NJKWbngIn8h"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}